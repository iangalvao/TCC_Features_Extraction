{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a11b4f",
   "metadata": {},
   "source": [
    "# Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44363cb5",
   "metadata": {},
   "source": [
    "# Índice:\n",
    "   * [Descrição](#description)\n",
    "      * [Objetivos](#goals)\n",
    "   * [Imports](#imports)\n",
    "   * [Extrção e Transformação](#extraction)\n",
    "   * [Parâmtetros](#parameters)\n",
    "      * [Introdução a Modelos de Árvores de Decisão](#decisiontree)\n",
    "      * [Espaço de Busca](#searchspace)\n",
    "      * [Log no MLFlow](#mlflow) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd51f4f",
   "metadata": {},
   "source": [
    "## Descrição <a class=\"anchor\" id=\"description\"></a>\n",
    "\n",
    "No primeiro notebook foi treinado um modelo simples de regressão linear e seu desempenho foi metrificado e a importância das características implementadas foi analisado. Tanto as métricas quanto os coeficientes das características foram calculados em um único valor. Neste notebook é implementada a técnica de validação cruzada para calcular um intervalo de confiância para cada métrica e coeficiente.\n",
    "\n",
    "Com validação cruzada do tipo k-folds, ao invés de se medir o desempenho do modelo em com um conjunto de testes e de treino fixo, é feito um particionamento da totalidade dos dados em k conjuntos distintos. Em cada iteração um destes conjuntos é usado como teste e o restante como treino, e o modelo resultante é avaliado com o conjunto de métricas. \n",
    "No final de todas as iterações, são computados a média e o desvio padrão de cada métrica. Dessa forma, o valor final é menos dependente da escolha do conjunto de treino e de teste e a totalidade dos dados é usada para se efetuar os testes.\n",
    "\n",
    "### Objetivos  <a class=\"anchor\" id=\"goals\"></a>\n",
    "   * Entender a técninca de validação cruzada,\n",
    "   * aplicar CV ao modelo linear,\n",
    "   * desenvolver funções para a análise dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866340cc",
   "metadata": {},
   "source": [
    "## Imports  <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671e37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from tabnanny import verbose\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from itertools import chain, combinations\n",
    "import datetime\n",
    "import tempfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.utils.mlflow_tags import MLFLOW_PARENT_RUN_ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b845d",
   "metadata": {},
   "source": [
    "## Extração e Transformação <a class=\"anchor\" id=\"extraction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f950731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(url):\n",
    "    return pd.read_csv(os.path.abspath(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4509def",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(\"../extracao/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fa6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(df):\n",
    "    r_state = 15\n",
    "    df = shuffle(df, random_state=r_state)\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    return X, y\n",
    "r_state = 12\n",
    "X, y = getXy(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=r_state\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175beb38",
   "metadata": {},
   "source": [
    "## Treinamento <a class=\"anchor\" id=\"training\"></a>\n",
    "\n",
    "Aqui é definida uma estratégia de validação cruzada, que é feita com o método k-folds utilizando 8 folds. As métricas são as definidas no último notebook: raíz do erro quadrático médio, erro absoluto médio e coeficiente de determinação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd08e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, _X, _y, _cv):\n",
    "    _scoring = [\"r2\", \"neg_mean_absolute_error\", \"neg_root_mean_squared_error\"]\n",
    "    results = cross_validate(estimator=model, X=_X, y=_y, cv=_cv, scoring=_scoring)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc69d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= make_pipeline(StandardScaler(), LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15c88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_validation(model,X, y, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f500ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.32531357, 0.00421739, 0.00339985, 0.00335693, 0.00358605,\n",
       "        0.00336933, 0.00335431, 0.00368881]),\n",
       " 'score_time': array([0.01016212, 0.00247717, 0.00189805, 0.00192094, 0.00193977,\n",
       "        0.00192165, 0.00201154, 0.00194788]),\n",
       " 'test_r2': array([0.17411628, 0.17459729, 0.19439588, 0.19286014, 0.1996818 ,\n",
       "        0.18111883, 0.19396096, 0.15352567]),\n",
       " 'test_neg_mean_absolute_error': array([-10.75934087, -10.57516785, -10.75875503, -10.68354239,\n",
       "        -10.329878  , -10.68127985, -10.41664408, -10.85006594]),\n",
       " 'test_neg_root_mean_squared_error': array([-13.44744964, -13.24817279, -13.56784077, -13.62223613,\n",
       "        -13.23660009, -13.59349831, -13.02502461, -13.75203714])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e973c",
   "metadata": {},
   "source": [
    "## Validação <a class=\"anchor\" id=\"validation\"></a>\n",
    "\n",
    "Para a validação das métricas foi escrita uma função que produz um intervalo de confiância de ... para cada métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9f25504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics_cv(cv):\n",
    "    rmse = cv[\"test_neg_root_mean_squared_error\"].mean()\n",
    "    rmseStd = cv[\"test_neg_root_mean_squared_error\"].std()\n",
    "    mae = cv[\"test_neg_mean_absolute_error\"].mean()\n",
    "    maeStd = cv[\"test_neg_mean_absolute_error\"].std()\n",
    "    r2 = cv[\"test_r2\"].mean()\n",
    "    r2Std = cv[\"test_r2\"].std()\n",
    "    return {\n",
    "            \"rmse\":[rmse, rmseStd],\n",
    "            \"mae\":[mae, maeStd], \n",
    "            \"r2\":[r2, r2Std]\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27d3c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = eval_metrics_cv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4623ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_cv(scores):\n",
    "    for metric, score in scores.items():\n",
    "        mean = score[0]\n",
    "        std = score[1]\n",
    "        print (f\"{metric}: {mean:.2f} +/- {2*std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59b587a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: -13.44 +/- 0.46\n",
      "mae: -10.63 +/- 0.34\n",
      "r2: 0.18 +/- 0.03\n"
     ]
    }
   ],
   "source": [
    "print_metrics_cv(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e8f04",
   "metadata": {},
   "source": [
    "## Log no MLFlow <a class=\"anchor\" id=\"mlflow\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f27e6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectMLFlow(MLFlowAddr):\n",
    "    client = MlflowClient(tracking_uri=MLFlowAddr)\n",
    "    mlflow.set_tracking_uri(MLFlowAddr)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289ff278",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = connectMLFlow(\"http://172.27.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c08edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Simple Model\"\n",
    "try:\n",
    "    experiment_id = client.create_experiment(experiment_name)\n",
    "except:\n",
    "    experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "    \n",
    "experiment = mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "410ed6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"LinearRegression_default_params_CV\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    mlflow.log_metric(\"r2\", scores[\"r2\"][0])\n",
    "    mlflow.log_metric(\"r2_std\", scores[\"r2\"][1])\n",
    "    mlflow.log_metric(\"rmse\", abs(scores[\"rmse\"][0]))\n",
    "    mlflow.log_metric(\"rmse_std\", scores[\"rmse\"][1])\n",
    "    mlflow.log_metric(\"mae\", abs(scores[\"mae\"][0]))\n",
    "    mlflow.log_metric(\"mae_std\", scores[\"mae\"][1])\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd51f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pscore = permutation_test_score(LinearRegression(), X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
