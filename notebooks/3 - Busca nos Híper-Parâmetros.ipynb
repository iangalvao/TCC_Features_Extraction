{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da2080a",
   "metadata": {},
   "source": [
    "# Busca no Espaço de Configuração - Hiperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2942ad",
   "metadata": {},
   "source": [
    "# Índice:\n",
    "   * [Descrição](#description)\n",
    "      * [Objetivos](#goals)\n",
    "   * [Imports](#imports)\n",
    "   * [Extrção e Transformação](#extraction)\n",
    "   * [Parâmetros Alvos da Busca](#parameters)\n",
    "      * [Introdução a Modelos de Árvores de Decisão](#decisiontree)\n",
    "      * [Parâmetros do SKLearn](#sklearnparams)\n",
    "   * [Treinamento](#training)\n",
    "      * [Tipos de Busca](#searchspace)\n",
    "   * [Validação](#validation)\n",
    "   * [Log no MLFlow](#mlflow) \n",
    "      * [Métricas e Parâmetros](#logmetrics)\n",
    "      * [Artefato com os Resultados](#logartifact)\n",
    "   * [Busca Aleatorizada](#randomized)\n",
    "      * [Treinamento](#randomizedTraining)\n",
    "      * [Validação](#randomizedValidation)\n",
    "      * [Log no MLFlow](#randomizedMLFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c16f44",
   "metadata": {},
   "source": [
    "## Descrição <a class=\"anchor\" id=\"description\"></a>\n",
    "\n",
    "Esse notebook implementa a busca por híperparâmetros ótimos para o modelo de Árvore de Decisão. Esse modelo foi escolhido por ter um espaço de parâmetros com múltiplas dimensões e por possuir métodos que permitem analisar a tomada de decisão do modelo treinado.\n",
    "\n",
    "### Tipos de Busca <a class=\"anchor\" id=\"searchspace\"></a>\n",
    "\n",
    "São implementadas duas estratégias de busca nos híper-parâmetros: a busca randomizada e a busca em grade.\n",
    "\n",
    "Na busca randomizada são passados uma distribuição de probabilididades para cada parâmetro e o número de iterações. O algoritmo irá gerar valores aleatórios de acordo com a distribuição para cada iteração.\n",
    "\n",
    "Na busca em grade são passados um conjunto de valores para cada parâmetro e o algoritmo executará todas as combinações. \n",
    "\n",
    "Em ambos os casos, são passadas métricas de desempenho e uma delas deve ser determinada como o _score_ a ser utilizado na seleção do melhor modelo. Por motivos de otimização, a biblioteca _Sklearn_ utiliza funções de métricas que são maiores quanto melhor o modelo. Com isso as funções de erro absoluto (funções as quais um valor menor indica um modelo melhor) são multiplicadas por -1, para que cresçam conforme o desempenho do modelo melhora.\n",
    "\n",
    "### Objetivos  <a class=\"anchor\" id=\"goals\"></a>\n",
    "\n",
    "* desenvolver funções para a busca nos híperparâmetros (incluindo a validação e log no MLFlow),\n",
    "* realizar a análise do desempenho do modelo no espaço dos parâmetros,\n",
    "* entender como o modelo de arvore de decisão se aplica aos dados do problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0744148",
   "metadata": {},
   "source": [
    "## Imports  <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f218f5a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "import sys\n",
    "from tabnanny import verbose\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from itertools import chain, combinations\n",
    "import datetime\n",
    "import tempfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import artifacts\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.utils.mlflow_tags import MLFLOW_PARENT_RUN_ID\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a06d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe848c3",
   "metadata": {},
   "source": [
    "## Extração e Transformação <a class=\"anchor\" id=\"extraction\"></a>\n",
    "\n",
    "A busca nos híper-parâmetros é feita no conjunto de treino, e o algoritmo de validação cruzada separa uma porção desse conjunto a cada iteração para usar como teste. Ao final, se o objetivo for produzir um modelo treinado, é utilizado um conjunto de validação para aferir o desempenho do melhor estimador encontrado na busca.\n",
    "\n",
    "Abaixo são separados os conjuntos de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99062667",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_data(url):\n",
    "    return pd.read_csv(os.path.abspath(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e72e1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = read_data(\"../extracao/datanov2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30382431",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getXy(df):\n",
    "    r_state = 15\n",
    "    df = shuffle(df, random_state=r_state)\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    return X, y\n",
    "random_state = 10\n",
    "X, y = getXy(df)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=random_state\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5485e5d",
   "metadata": {},
   "source": [
    "## Parâmetros Alvos da Busca<a class=\"anchor\" id=\"parameters\"></a>\n",
    "\n",
    "### Introdução a Modelos de Árvores de Decisão <a class=\"anchor\" id=\"decisiontree\"></a>\n",
    "\n",
    "Uma breve descrição do modelo de árvore de decisão é necessária para proceder na busca por híper-parâmetros, com o intuito de se entender melhor os argumentos os quais se deseja maximizar.\n",
    "\n",
    "Árvores de decisão são grafos acíclicos que podem ser usados para realizar decisões. Em cada nó interno da árvore possui um índice de uma das características e um limiar. Um input que seja analisado nesse nó seguirá na subárvore à esquerda desse nó se o valor da característica indexada no nó for menor que o limiar, e seguirá na subárvore da direita caso contrário. Nas folhas é feita a previsão, que é constante para todos os nós que terminarem de percorrer a árvore naquele nó. Dessa forma, uma árvore é uma aproximação  constante em trechos do domínio.\n",
    "\n",
    "### Parâmetros do SKLearn<a class=\"anchor\" id=\"sklearnparams\"></a>:\n",
    "   * _max_depth_ : limita a altura máxima da árvore. Conforme a altura cresce, o modelo fica mais complexo, isso pode aumentar a performace, mas também pode levar a _over fitting_.\n",
    "   * _max_features_ : Determina o número máximo de características a serem utilizadas nos nós internos da árvore para dividir as amostras.\n",
    "   * _min_samples_split_ : número mínimo de amostras para dividir uma folha, transformando-a em um nó interno com duas folhas.\n",
    "   * _min_samples_leaf_ : número mínimo de amostras permitidas em uma folha.\n",
    "   \n",
    "O parâmetro _max_depth_ é o príncipal parâmetro para regular o desempenho e o _over fitting_, mas note que os dois últimos parâmetros podem também ter influência na altura final da árvore, se os valores forem sufientemente altos para o conjunto de dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b207017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "range_grid = {\n",
    "    \"max_features\":[ 6, 7, 1],\n",
    "    \"max_depth\": [ 1, 20, 2],\n",
    "    \"min_samples_split\": [ 5, 600, 30],\n",
    "    \"min_samples_leaf\": [ 5, 600, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c43b8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "for k, v in range_grid.items():\n",
    "        param_grid[k] = range(v[0], v[1], v[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909a044f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': range(6, 7),\n",
       " 'max_depth': range(1, 20, 2),\n",
       " 'min_samples_split': range(5, 600, 30),\n",
       " 'min_samples_leaf': range(5, 600, 30)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9516869",
   "metadata": {},
   "source": [
    "## Métricas<a class=\"anchor\" id=\"metrics\"></a>\n",
    "\n",
    "As métricas utilizadas são as mesmas dos últimos modelos: raíz do erro quadrático médio, erro absoluto médio e coeficiente de determinação (r2). Essa última é utilizada como _score_ pela busca em grade para determinar o melhor modelo, que será retreinado utilizando todo conjunto de treino, após a etapa de busca dos melhores parâmetros. Esse retreinamento (refit) permite tanto a validação do modelo na parcela dos dados não utilizada na busca quanto o log do modelo no MLFlow, que poderá ser baixado para uma análise posterior ou mesmo para um possível _deploy_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25257102",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_scoring = [\n",
    "    \"r2\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "    \"neg_root_mean_squared_error\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc6e8b",
   "metadata": {},
   "source": [
    "## Treinamento <a class=\"anchor\" id=\"training\"></a>\n",
    "\n",
    "Nesta etapa é treinado o modelo de Árvore de Decisão. O log do modelo no MLFlow é feito logo após o treinamento, por conta de uma limitação da API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f526c87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def connectMLFlow(MLFlowAddr):\n",
    "    client = MlflowClient(tracking_uri=MLFlowAddr)\n",
    "    mlflow.set_tracking_uri(MLFlowAddr)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8cc45c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "client = connectMLFlow(\"http://172.27.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2957e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment_name = \"HiperParameter Search\"\n",
    "try:\n",
    "    experiment_id = client.create_experiment(experiment_name)\n",
    "except:\n",
    "    experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "    \n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "run_name = \"DecisionTree GridSearch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e82b9702",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "skmodel = DecisionTreeRegressor()\n",
    "gridSearchModel = GridSearchCV(\n",
    "    skmodel, param_grid, scoring=_scoring, refit=\"neg_mean_absolute_error\", verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca244628",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_start = time()\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "    gridSearchModel.fit(X_train, y_train)\n",
    "    mlflow.sklearn.log_model(gridSearchModel.best_estimator_,\"model/\")\n",
    "    mlflow.end_run()\n",
    "grid_end = time()\n",
    "grid_run_time = grid_end - grid_start\n",
    "\n",
    "print (\"Tempo para rodar essa célula: {}m {:.3f}s\".format(int(grid_run_time/60), grid_run_time%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e64d0",
   "metadata": {},
   "source": [
    "## Validação <a class=\"anchor\" id=\"validation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3185e6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e1c43473",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho no conjunto de Treino\n",
      "rmse:12.522044099688351    mae:9.710029222228924    r2:0.3509999859058073\n",
      "Desempenho no conjunto de Testes (Validação)\n",
      "rmse:13.094651272942938    mae:10.139468613569443    r2:0.25446618941123145\n"
     ]
    }
   ],
   "source": [
    "gridPredictionVal = gridSearchModel.predict(X_val)\n",
    "gridPredictionTrain = gridSearchModel.predict(X_train)\n",
    "\n",
    "rmse, mae, r2 = eval_metrics(y_train, gridPredictionTrain)\n",
    "print (f\"Desempenho no conjunto de Treino\\nrmse:{rmse}    mae:{mae}    r2:{r2}\")\n",
    "\n",
    "rmse, mae, r2 = eval_metrics(y_val, gridPredictionVal)\n",
    "print (f\"Desempenho no conjunto de Testes (Validação)\\nrmse:{rmse}    mae:{mae}    r2:{r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1f02cf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'max_features': 6,\n",
       " 'min_samples_leaf': 35,\n",
       " 'min_samples_split': 125}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchModel.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560270f1",
   "metadata": {},
   "source": [
    "## Log no MLFlow <a class=\"anchor\" id=\"mlflow\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "92e8242d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def logCVResultsCSV(cv_results, run_id, mlclient ):\n",
    "\n",
    "    tempdir = tempfile.TemporaryDirectory(suffix=None, prefix=None, dir=None)\n",
    "    tmpname = tempdir.name\n",
    "    \n",
    "    filename = \"cv_results.csv\"\n",
    "    csv = os.path.join(tmpname, filename)\n",
    "    \n",
    "    pd.DataFrame(cv_results).to_csv(csv, index=False)\n",
    "    \n",
    "    mlclient.log_artifact(run_id,csv, \"cv_results\")\n",
    "    tempdir.cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c62ce9f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tags = {\"search_type\":\"GridSearchCV\"}\n",
    "tags = [mlflow.entities.RunTag(k,v) for k,v in tags.items()]\n",
    "\n",
    "search_params = {\"param_grid\":str(param_grid),\n",
    "                 \"scoring\":str(_scoring),\n",
    "                 \"refit\":\"neg_mean_absolute_error\",\n",
    "                 \"estimator\":\"DecisionTreeRegressor\",\n",
    "                }\n",
    "search_params = [mlflow.entities.Param(k,v) for k,v in search_params.items()]\n",
    "\n",
    "metrics = {\"rmse\":rmse, \"mae\":mae, \"r2\":r2}\n",
    "now = int(time())\n",
    "metrics = [mlflow.entities.Metric(k,v,now,1) for k,v in metrics.items()]\n",
    "client.log_batch(run_id, metrics = metrics, params=search_params,tags = tags)\n",
    "    \n",
    "logCVResultsCSV(gridSearchModel.cv_results_, run_id, client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed6f9c",
   "metadata": {},
   "source": [
    "## Busca Aleatorizada<a class=\"anchor\" id=\"randomized\"></a>\n",
    "\n",
    "Aqui é feita uma busca aleatorizada com os mesmos parâmetros da busca em grade. Serão geradas 500 amostras, o que permite buscar o mesmo espaço de parâmetros de forma mais rápida, já que a busca por grade gerou 20000 diferentes combinações de parâmetros. No notebook seguinte está uma análise comparativa dos resultados, mas já podemos observar o desempenho na etapa de validação.\n",
    "\n",
    "Como dito anteriormente, na busca aleatorizada são geradas amostras dos parâmetros com base em uma distribuição passada para cada um. Neste caso a distribuição foi constante para todos os parâmetros.\n",
    "\n",
    "### Treinamento <a class=\"anchor\" id=\"randomizedTraining\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "127e9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"DecisionTree RandomSearch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4ef3af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 500\n",
    "randSearchModel = RandomizedSearchCV(\n",
    "    skmodel, param_grid, scoring=_scoring, refit=\"neg_mean_absolute_error\", verbose=0, n_iter=n_iter, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0e15f965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo para rodar essa célula: 0m 32.189s\n"
     ]
    }
   ],
   "source": [
    "rand_start = time()\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "    randSearchModel.fit(X_train, y_train)\n",
    "    mlflow.sklearn.log_model(randSearchModel.best_estimator_,\"model/\")\n",
    "    mlflow.end_run()\n",
    "rand_end = time()\n",
    "rand_runtime = rand_end - rand_start\n",
    "print (\"Tempo para rodar essa célula: {}m {:.3f}s\".format(int(rand_runtime/60), rand_runtime%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb50a8",
   "metadata": {},
   "source": [
    "### Validação<a class=\"anchor\" id=\"randomizedValidation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7fd21f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho no conjunto de Treino\n",
      "rmse:12.432063053099698    mae:9.635086784446763    r2:0.3602936575478374\n",
      "\n",
      "Desempenho no conjunto de Testes (Validação)\n",
      "rmse:13.11803015523809    mae:10.15401971046676    r2:0.25180169592126034\n",
      "\n",
      "Tempo de busca: 32.189s\n"
     ]
    }
   ],
   "source": [
    "randPredictVal = randSearchModel.predict(X_val)\n",
    "randPredictTrain = randSearchModel.predict(X_train)\n",
    "\n",
    "rmse, mae, r2 = eval_metrics(y_train, randPredictTrain)\n",
    "print (f\"Desempenho no conjunto de Treino\\nrmse:{rmse}    mae:{mae}    r2:{r2}\")\n",
    "\n",
    "rmse, mae, r2 = eval_metrics(y_val, randPredictVal)\n",
    "print (f\"\\nDesempenho no conjunto de Testes (Validação)\\nrmse:{rmse}    mae:{mae}    r2:{r2}\")\n",
    "print (\"\\nTempo de busca: {:.3f}s\".format(rand_end-rand_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa22518",
   "metadata": {},
   "source": [
    "Vemos que o modelo encontrado apresentou um desempenho similar do que o da busca por grade, mesmo com menos tempo de treino. Abaixo estão os valores dos parâmetros do modelo de melhor desempenho na busca e as previsões feitas pelo modelo comparadas com os valores verdadeiros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a6fbf9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 125,\n",
       " 'min_samples_leaf': 35,\n",
       " 'max_features': 6,\n",
       " 'max_depth': 11}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randSearchModel.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fd426",
   "metadata": {},
   "source": [
    "### Log no MLFlow<a class=\"anchor\" id=\"randomizedMLFlow\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f1bd757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"search_type\":\"RandomSearchCV\"}\n",
    "tags = [mlflow.entities.RunTag(k,v) for k,v in tags.items()]\n",
    "\n",
    "search_params = {\"param_distributions\":str(param_grid),\n",
    "                 \"scoring\":str(_scoring),\n",
    "                 \"refit\":\"neg_mean_absolute_error\",\n",
    "                 \"n_iter\":str(n_iter),\n",
    "                 \"estimator\":\"DecisionTreeRegressor\",\n",
    "                \"random_state\":str(random_state)}\n",
    "search_params = [mlflow.entities.Param(k,v) for k,v in search_params.items()]\n",
    "\n",
    "metrics = {\"rmse\":rmse, \"mae\":mae, \"r2\":r2}\n",
    "now = int(time()*1000)\n",
    "metrics = [mlflow.entities.Metric(k,v,now,1) for k,v in metrics.items()]\n",
    "client.log_batch(run_id, metrics = metrics, params=search_params,tags = tags)\n",
    "    \n",
    "logCVResultsCSV(randSearchModel.cv_results_, run_id, client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb12c7",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    " * Tentar mudar o log do mlflow para ficar separado do treino. Usar start_run(run_id) com run_id vindo de create_run.\n",
    " * Checar os nomes. Passar camelCase para under_score.\n",
    " * Revisar a descrição.\n",
    " * Logar no Mlflow o train/test split e random state associado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
